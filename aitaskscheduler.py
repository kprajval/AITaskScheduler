# -*- coding: utf-8 -*-
"""AITaskScheduler.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SRlVwkY-SSwOTdS-mhIipusVJtwk-ywl
"""

import psutil
import time
import numpy as np
from collections import deque
from sklearn.cluster import KMeans
from torch import nn
import torch
import torch.optim as optim
import json
import pickle
from typing import Dict, List
import threading
import random
from concurrent.futures import ThreadPoolExecutor
import sys # For ContextManager
# import math # Not needed as QuantumScheduler is removed

# Placeholder classes for context handlers and networkx
class WindowsContextHandler:
    def get_foreground_process(self):
        return "Not Implemented on this OS"

class MacContextHandler:
    def get_foreground_process(self):
        return "Not Implemented on this OS"

class LinuxContextHandler:
    def get_foreground_process(self):
        return "Not Implemented on this OS"

class AITaskScheduler:
    def __init__(self):
        self.monitor = SystemMonitor()
        self.learner = ReinforcementLearner()
        self.task_queue = TaskQueue()
        self.models = {
            'time_predictor': TimePredictor(),
            'priority_adjuster': PriorityAdjuster()
        }
        self.config = self.load_config()

    def load_config(self):
        try:
            with open('config.json') as f:
                return json.load(f)
        except FileNotFoundError:
            return {
                'learning_rate': 0.001,
                'exploration_rate': 0.3,
                'history_size': 1000
            }

class SystemMonitor:
    def __init__(self):
        self.metrics_history = {
            'cpu': deque(maxlen=1000),
            'memory': deque(maxlen=1000),
            'disk': deque(maxlen=1000),
            'network': deque(maxlen=1000),
        }
        self.task_history = []
        self.resource_thresholds = {
            'cpu': 80,  # %
            'memory': 90 # %
        }
        self._running = False # Control flag for the monitoring loop

    def collect_metrics(self):
        """Collects current system metrics."""
        cpu_percent = psutil.cpu_percent(interval=None) # No interval here, as we control the loop
        memory_percent = psutil.virtual_memory().percent
        disk_busy_time = psutil.disk_io_counters().busy_time
        net_bytes_sent_recv = psutil.net_io_counters().bytes_sent + psutil.net_io_counters().bytes_recv
        timestamp = time.time()

        metrics = {
            'cpu': cpu_percent,
            'memory': memory_percent,
            'disk': disk_busy_time,
            'network': net_bytes_sent_recv,
            'timestamp': timestamp
        }

        # Append to history
        self.metrics_history['cpu'].append(cpu_percent)
        self.metrics_history['memory'].append(memory_percent)
        self.metrics_history['disk'].append(disk_busy_time)
        self.metrics_history['network'].append(net_bytes_sent_recv)

        return metrics

    def log_task(self, task: Dict):
        """Log task execution details"""
        # Ensure 'metrics' key exists or add it
        if 'metrics' not in task:
            task['metrics'] = self.collect_metrics() # Collect metrics at the time of logging if not already present
        self.task_history.append(task)
        if len(self.task_history) > 1000:
            self.task_history.pop(0)

    def continuous_monitoring(self, interval=1):
        """
        Continuously collects and stores system metrics at specified intervals.
        This function should be run in a separate thread.
        """
        self._running = True
        while self._running:
            self.collect_metrics()
            time.sleep(interval)

    def stop_monitoring(self):
        """Stops the continuous monitoring loop."""
        self._running = False

class TimePredictor(nn.Module):
    def __init__(self, input_size=6, hidden_size=32):
        super(TimePredictor, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, 1)
        )

    def forward(self, x):
        return self.net(x)

class PriorityAdjuster:
    def __init__(self):
        self.cluster_model = KMeans(n_clusters=5, n_init=10)
        self.cluster_centers = None

    def _extract_features(self, tasks: List[Dict]):
        """
        Extracts features from tasks for clustering.
        Example features: priority, estimated_duration, CPU/memory requirements.
        You'll need to define what features are relevant for clustering your tasks.
        """
        features = []
        for task in tasks:
            # Example features, adjust based on your task structure
            cpu_req = task['requirements'].get('cpu', 0)
            mem_req = task['requirements'].get('memory', 0)
            est_duration = task.get('estimated_duration', 1)
            priority = task.get('priority', 50)
            features.append([cpu_req, mem_req, est_duration, priority])
        return np.array(features)

    def fit(self, tasks: List[Dict]):
        if not tasks:
            return
        features = self._extract_features(tasks)
        if features.shape[0] < self.cluster_model.n_clusters:
            print("Warning: Not enough samples to form clusters. Adjust n_clusters or provide more data.")
            self.cluster_centers = None
            return
        self.cluster_model.fit(features)
        self.cluster_centers = self.cluster_model.cluster_centers_

    def predict_priority(self, task: Dict):
        features = self._extract_features([task])
        if self.cluster_centers is None or features.shape[0] == 0:
            return task.get('priority', 50) # Return original priority if no clusters are fitted
        distances = np.linalg.norm(self.cluster_centers - features[0], axis=1)
        # Map clusters to priorities: closer to cluster 0 (arbitrarily) means higher priority
        # Adjust mapping as needed based on your cluster interpretation
        return 100 - (np.argmin(distances) * (100 / self.cluster_model.n_clusters))

class ReinforcementLearner:
    def __init__(self):
        self.model = self._build_model()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        self.memory = deque(maxlen=10000)
        self.gamma = 0.95

    def _build_model(self):
        return nn.Sequential(
            nn.Linear(8, 32),
            nn.ReLU(),
            nn.Linear(32, 32),
            nn.ReLU(),
            nn.Linear(32, 3)  # Three actions: delay, execute now, preempt
        )

    def remember(self, state, action, reward, next_state):
        self.memory.append((state, action, reward, next_state))

    def get_action(self, state, exploration_rate=0.1):
        if np.random.rand() < exploration_rate:
            return np.random.randint(3)
        state_tensor = torch.FloatTensor(state)
        self.model.eval() # Set model to evaluation mode
        with torch.no_grad(): # No gradient calculation needed for inference
            act_values = self.model(state_tensor)
        self.model.train() # Set model back to training mode
        return torch.argmax(act_values).item()

    def replay(self, batch_size=32):
        if len(self.memory) < batch_size:
            return

        minibatch = random.sample(self.memory, batch_size)
        states, actions, rewards, next_states = zip(*minibatch)

        states_tensor = torch.FloatTensor(np.array(states))
        actions_tensor = torch.LongTensor(actions)
        rewards_tensor = torch.FloatTensor(rewards)

        # Filter out None next_states for terminal states
        non_final_mask = torch.tensor([s is not None for s in next_states], dtype=torch.bool)
        non_final_next_states = torch.FloatTensor([s for s in next_states if s is not None])

        current_q_values = self.model(states_tensor).gather(1, actions_tensor.unsqueeze(1)).squeeze(1)

        next_q_values = torch.zeros(batch_size)
        if non_final_next_states.shape[0] > 0:
            next_q_values[non_final_mask] = self.model(non_final_next_states).max(1)[0].detach()

        expected_q_values = rewards_tensor + self.gamma * next_q_values

        self.optimizer.zero_grad()
        loss = nn.MSELoss()(current_q_values, expected_q_values)
        loss.backward()
        self.optimizer.step()

class TaskQueue:
    def __init__(self):
        self.queue = []
        self.lock = threading.Lock()

    def add_task(self, task: Dict):
        with self.lock:
            # Basic validation
            required_fields = {'name', 'priority', 'requirements'}
            if not all(field in task for field in required_fields):
                raise ValueError("Task missing required fields")

            self.queue.append(task)
            self.queue.sort(key=lambda x: x['priority'], reverse=True)

    def get_next_task(self):
        with self.lock:
            if not self.queue:
                return None
            return self.queue.pop(0)

    def reschedule_task(self, task):
        with self.lock:
            self.queue.append(task)
            self.queue.sort(key=lambda x: x['priority'], reverse=True)

class SchedulingEngine:
    def __init__(self, scheduler_instance):
        self.scheduler = scheduler_instance # Pass the scheduler instance
        self.running = True
        self.performance_log = []
        self.task_executor = TaskExecutor(self.scheduler) # Initialize executor here

    def run(self):
        """Main scheduling loop"""
        while self.running:
            current_metrics = self.scheduler.monitor.collect_metrics()
            task = self.scheduler.task_queue.get_next_task()

            if task:
                decision = self._make_scheduling_decision(task, current_metrics)
                self._execute_decision(task, decision)
            else:
                # If no tasks, perhaps run learner replay or do nothing
                self.scheduler.learner.replay() # Allow the learner to train even if no tasks
            time.sleep(0.1)  # Prevent CPU overload

    def _make_scheduling_decision(self, task, metrics):
        """Use AI models to make scheduling decisions"""
        # Feature engineering
        features = [
            metrics['cpu'],
            metrics['memory'],
            task['priority'],
            task['requirements'].get('cpu', 0),
            task['requirements'].get('memory', 0),
            len(self.scheduler.task_queue.queue),
            time.time() - task.get('created_time', time.time()),
            self._calculate_urgency(task) # This method needs to be implemented
        ]

        # Ensure features list has the correct size for the TimePredictor (input_size=6)
        # and ReinforcementLearner (input_size=8)
        # Here, features[:6] for time_predictor and full features for learner
        if len(features) < 8:
            # Pad or adjust features if they are less than expected by RL model
            # This is a basic example; you should ensure your feature engineering aligns
            # with your model's input size.
            features.extend([0] * (8 - len(features)))

        # Get AI recommendations
        action = self.scheduler.learner.get_action(features)
        predicted_time = self.scheduler.models['time_predictor'](
            torch.FloatTensor(features[:6])
        ).item()

        return {
            'action': action,
            'predicted_time': predicted_time,
            'features': features
        }

    def _execute_decision(self, task, decision):
        """Executes the scheduling decision using the TaskExecutor."""
        # The TaskExecutor needs to be aware of the decision
        self.task_executor.execute_task(task, decision)

    def _calculate_urgency(self, task: Dict) -> float:
        """
        Calculates the urgency of a task.
        This is a placeholder and should be implemented based on your criteria,
        e.g., deadline, priority, time spent in queue.
        """
        # Example: Urgency increases with time spent in queue and task priority
        time_in_queue = time.time() - task.get('created_time', time.time())
        urgency = time_in_queue * (task.get('priority', 50) / 100.0) # Scale priority 0-1
        return urgency

class TaskExecutor:
    def __init__(self, scheduler):
        self.scheduler = scheduler
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        self.current_tasks = {}

    def execute_task(self, task, decision):
        """Execute task based on scheduling decision"""
        if decision['action'] == 0:  # Delay
            task['priority'] = max(1, task['priority'] - 10) # Reduce priority
            print(f"Task '{task['name']}' delayed. New priority: {task['priority']}")
            self.scheduler.task_queue.reschedule_task(task)
            return
        elif decision['action'] == 2: # Preempt - this requires more complex logic
            print(f"Task '{task['name']}' selected for preemption, but preemption logic is not implemented.")
            # For a real system, you'd need to pause/stop an existing task
            # and potentially reschedule it or handle its state.
            self.scheduler.task_queue.reschedule_task(task) # For now, just reschedule if preempted
            return

        print(f"Executing task: {task['name']} with predicted time {decision['predicted_time']:.2f}s")
        future = self.thread_pool.submit(self._run_task, task)
        self.current_tasks[task['name']] = {
            'future': future,
            'start_time': time.time(),
            'task': task,
            'decision': decision # Store the decision for learning
        }
        future.add_done_callback(self._task_complete_callback)

    def _run_task(self, task):
        """Actual task execution logic"""
        # This would be replaced with actual task execution
        try:
            duration = task.get('estimated_duration', 1)
            time.sleep(duration)
            print(f"Task '{task['name']}' completed successfully in {duration:.2f}s.")
            return True
        except Exception as e:
            print(f"Task '{task['name']}' failed: {e}")
            return False

    def _task_complete_callback(self, future):
        """Handle task completion"""
        task_name = None
        for k, v in self.current_tasks.items():
            if v['future'] == future:
                task_name = k
                break

        if task_name is None:
            print("Error: Completed task not found in current_tasks.")
            return

        task_data = self.current_tasks.pop(task_name)
        task_info = task_data['task']
        start_time = time.time() # Should be task_data['start_time']
        end_time = time.time()
        success = future.result()
        actual_duration = end_time - task_data['start_time'] # Corrected calculation

        print(f"Callback for task '{task_info['name']}'. Success: {success}, Actual Duration: {actual_duration:.2f}s")

        # Log results
        result = {
            'task': task_info,
            'start_time': task_data['start_time'], # Use stored start time
            'end_time': end_time,
            'success': success,
            'actual_duration': actual_duration,
            'predicted_duration': task_data['decision']['predicted_time'],
            'metrics_at_completion': self.scheduler.monitor.collect_metrics() # Log metrics at completion
        }

        # Update learning models
        next_state_features = [
            result['metrics_at_completion']['cpu'],
            result['metrics_at_completion']['memory'],
            task_info['priority'],
            task_info['requirements'].get('cpu', 0),
            task_info['requirements'].get('memory', 0),
            len(self.scheduler.task_queue.queue),
            0, # Time in queue for the *next* state (as this task is done)
            0  # Urgency for the *next* state (as this task is done)
        ]
        if len(next_state_features) < 8:
            next_state_features.extend([0] * (8 - len(next_state_features)))


        self.scheduler.learner.remember(
            task_data['decision']['features'], # State when decision was made
            task_data['decision']['action'],
            self._calculate_reward(result), # Calculate reward based on outcome
            next_state_features # Pass the next state features
        )

        self.scheduler.monitor.log_task(result)

    def _calculate_reward(self, result: Dict) -> float:
        """
        Calculates the reward for the reinforcement learner.
        Positive reward for success, negative for failure.
        Reward also considers deviation from predicted time and resource usage.
        """
        reward = 0.0

        if result['success']:
            reward += 10.0 # Base reward for success
        else:
            reward -= 20.0 # Penalty for failure

        # Reward based on meeting predicted duration
        time_diff = abs(result['actual_duration'] - result['predicted_duration'])
        if time_diff < 0.5: # Close to predicted
            reward += 5.0
        elif time_diff < 2.0: # Moderate deviation
            reward += 1.0
        else: # Large deviation
            reward -= 5.0

        # Penalize high resource usage (simple example)
        cpu_usage = result['metrics_at_completion'].get('cpu', 0)
        memory_usage = result['metrics_at_completion'].get('memory', 0)

        if cpu_usage > self.scheduler.monitor.resource_thresholds['cpu']:
            reward -= (cpu_usage - self.scheduler.monitor.resource_thresholds['cpu']) * 0.1
        if memory_usage > self.scheduler.monitor.resource_thresholds['memory']:
            reward -= (memory_usage - self.scheduler.monitor.resource_thresholds['memory']) * 0.1

        return reward

class PersistenceManager:
    @staticmethod
    def save_model(model, path):
        torch.save(model.state_dict(), path)

    @staticmethod
    def load_model(model, path):
        try:
            model.load_state_dict(torch.load(path))
            model.eval() # Set to evaluation mode after loading
            return model
        except FileNotFoundError:
            print(f"Model file not found: {path}. Initializing with new model.")
            return model # Return original model if file not found
        except Exception as e:
            print(f"Error loading model from {path}: {e}. Initializing with new model.")
            return model

    @staticmethod
    def save_history(history, path):
        with open(path, 'wb') as f:
            pickle.dump(history, f)

    @staticmethod
    def load_history(path):
        try:
            with open(path, 'rb') as f:
                return pickle.load(f)
        except (FileNotFoundError, EOFError):
            print(f"History file not found or empty: {path}. Starting with empty history.")
            return []
        except Exception as e:
            print(f"Error loading history from {path}: {e}. Starting with empty history.")
            return []

class MetaLearner:
    """System that continuously optimizes the learning process itself"""
    def __init__(self, main_scheduler):
        self.scheduler = main_scheduler
        self.hyperparameter_space = {
            'learning_rate': (0.0001, 0.01),
            'batch_size': (16, 256),
            'gamma': (0.8, 0.99)
        }
        self.current_config = self._get_default_config()

    def _get_default_config(self):
        return {
            'learning_rate': 0.001,
            'batch_size': 32,
            'gamma': 0.95
        }

    def _apply_config(self, lr, bs, gamma):
        self.scheduler.learner.optimizer = optim.Adam(self.scheduler.learner.model.parameters(), lr=lr)
        self.scheduler.learner.gamma = gamma
        # batch_size is used in replay, not a direct attribute to set here
        # self.scheduler.learner.batch_size = bs

    def optimize_hyperparameters(self):
        """Use Bayesian optimization to find optimal parameters"""
        try:
            from skopt import gp_minimize
        except ImportError:
            print("scikit-optimize (skopt) not installed. Meta-learning optimization skipped.")
            return

        def objective(params):
            lr, bs, gamma = params
            self._apply_config(lr, bs, gamma)
            return -self._evaluate_performance()

        res = gp_minimize(
            objective,
            [self.hyperparameter_space['learning_rate'],
             self.hyperparameter_space['batch_size'],
             self.hyperparameter_space['gamma']],
            n_calls=10, # Reduced for faster execution in example
            random_state=42
        )
        self.current_config.update({
            'learning_rate': res.x[0],
            'batch_size': int(res.x[1]),
            'gamma': res.x[2]
        })

    def _evaluate_performance(self):
        """Evaluate current configuration performance"""
        recent_tasks = self.scheduler.monitor.task_history[-100:]
        if not recent_tasks:
            return 0

        # Calculate average success rate and average duration to reward better performance
        successful_tasks = [t for t in recent_tasks if t.get('success', False)]
        if not successful_tasks:
            return 0 # No successful tasks to evaluate

        avg_completion_time = sum(
            t['actual_duration'] for t in successful_tasks
        ) / len(successful_tasks)

        success_rate = len(successful_tasks) / len(recent_tasks)

        # A higher success rate is better, a lower completion time is better.
        # We want to maximize this value.
        # Avoid division by zero if avg_completion_time is very small.
        if avg_completion_time == 0:
            return success_rate * 1000 # Maximize if completion time is instant
        return success_rate / avg_completion_time

    def continuous_optimization(self, interval=3600):
        """Continuously run hyperparameter optimization."""
        while True:
            print("Running meta-learning optimization...")
            self.optimize_hyperparameters()
            print(f"Meta-learning complete. New config: {self.current_config}")
            time.sleep(interval)


class HardwareProfiler:
    """Advanced hardware capability detection and optimization"""
    def __init__(self):
        self.capabilities = self._detect_hardware()
        self.benchmarks = self._run_benchmarks()

    def _detect_hardware(self):
        """Comprehensive hardware detection"""
        try:
            import cpuinfo
        except ImportError:
            print("cpuinfo not installed. Please install it for full hardware profiling.")
            cpuinfo = None
        try:
            import torch.cuda
        except ImportError:
            print("PyTorch with CUDA not installed. GPU detection will be limited.")
            torch.cuda = None

        cpu_info_data = cpuinfo.get_cpu_info() if cpuinfo else {}

        return {
            'cpu': {
                'name': cpu_info_data.get('brand_raw', 'Unknown CPU'),
                'cores': psutil.cpu_count(logical=False),
                'threads': psutil.cpu_count(logical=True),
                'avx': 'avx' in cpu_info_data.get('flags', [])
            },
            'gpu': {
                'available': torch.cuda.is_available() if torch.cuda else False,
                'count': torch.cuda.device_count() if torch.cuda else 0,
                'memory': [torch.cuda.get_device_properties(i).total_memory
                           for i in range(torch.cuda.device_count())] if torch.cuda else []
            },
            'memory': {
                'total': psutil.virtual_memory().total,
                'swap': psutil.swap_memory().total
            },
            'disk': {
                'type': self._detect_disk_type(),
                'speed': None  # Will be set in benchmarks
            }
        }

    def _detect_disk_type(self):
        # This is a very basic placeholder. Real detection is complex.
        return "Unknown"

    def _run_benchmarks(self):
        """Run hardware performance benchmarks"""
        print("Running hardware benchmarks (placeholders)...")
        return {
            'cpu_speed': self._benchmark_cpu(),
            'disk_speed': self._benchmark_disk(),
            'memory_bandwidth': self._benchmark_memory()
        }

    def _benchmark_cpu(self):
        # Simple CPU benchmark
        start_time = time.time()
        _ = sum(i*i for i in range(10**6))
        return 1 / (time.time() - start_time)

    def _benchmark_disk(self):
        # Placeholder for disk benchmark (write/read a temp file)
        return 0.0 # Not implemented

    def _benchmark_memory(self):
        # Placeholder for memory benchmark
        return 0.0 # Not implemented

class ContextManager:
    """Understands user context and environmental factors"""
    def __init__(self):
        self.user_context = {
            'current_activity': None,
            'time_of_day': None,
            'power_status': None,
            'network_status': None
        }
        self.handler = self._init_context_handler()

    def _init_context_handler(self):
        """Initialize platform-specific context handlers"""
        if sys.platform == 'win32':
            return WindowsContextHandler()
        elif sys.platform == 'darwin':
            return MacContextHandler()
        else:
            return LinuxContextHandler()

    def update_context(self):
        """Refresh all context information"""
        self.user_context.update({
            'time_of_day': self._get_time_context(),
            'power_status': self._get_power_status(),
            'network_status': self._get_network_status(),
            'current_activity': self.handler.get_foreground_process()
        })

    def _get_time_context(self):
        hour = time.localtime().tm_hour
        if 5 <= hour < 12:
            return "morning"
        elif 12 <= hour < 18:
            return "afternoon"
        else:
            return "night"

    def _get_power_status(self):
        battery = psutil.sensors_battery()
        if battery:
            return "battery" if not battery.power_plugged else "ac"
        return "unknown"

    def _get_network_status(self):
        # This is a highly simplified placeholder.
        return "unknown"

    def should_defer_task(self, task):
        """Determine if task should be deferred based on context"""
        # Don't run heavy tasks on battery
        if (self.user_context['power_status'] == 'battery' and
            task['requirements'].get('cpu', 0) > 30):
            return True

        # Don't run bandwidth-heavy tasks on metered connections
        if (self.user_context['network_status'] == 'metered' and
            task['requirements'].get('network', 0) > 1000000):  # 1MB
            return True

        return False

    def continuous_update(self, interval=5):
        """Continuously update context information."""
        while True:
            self.update_context()
            time.sleep(interval)


# Placeholder for networkx (graph library) for demonstration
class nx:
    class DiGraph:
        def __init__(self):
            self._nodes = set()
            self._adj = {}
            self._indegree = {}

        def add_node(self, node):
            if node not in self._nodes:
                self._nodes.add(node)
                self._adj[node] = []
                self._indegree[node] = 0

        def add_edge(self, u, v):
            if u not in self._nodes: self.add_node(u)
            if v not in self._nodes: self.add_node(v)
            self._adj[u].append(v)
            self._indegree[v] += 1

    @staticmethod
    def topological_sort(graph):
        """
        Kahn's algorithm for topological sort.
        Raises NetworkXUnfeasible if a cycle is detected.
        """
        in_degree = graph._indegree.copy()
        q = deque([node for node in graph._nodes if in_degree[node] == 0])
        result = []
        count = 0

        while q:
            u = q.popleft()
            result.append(u)
            count += 1
            for v in graph._adj[u]:
                in_degree[v] -= 1
                if in_degree[v] == 0:
                    q.append(v)

        if count != len(graph._nodes):
            raise nx.NetworkXUnfeasible("Graph has a cycle.")
        return result

    class NetworkXUnfeasible(Exception):
        pass

class DependencyResolver:
    """Handles complex task dependencies and workflows"""
    def __init__(self):
        self.dependency_graph = nx.DiGraph()
        self.task_registry = {}

    def register_task(self, task):
        """Register a task and its dependencies"""
        self.task_registry[task['name']] = task
        self.dependency_graph.add_node(task['name'])

        for dep in task.get('dependencies', []):
            self.dependency_graph.add_edge(dep, task['name'])

    def get_execution_order(self, tasks):
        """Return optimal execution order considering dependencies"""
        try:
            # Need to build a subgraph of only the relevant tasks for topological sort
            subgraph = nx.DiGraph()
            task_names_in_queue = {t['name'] for t in tasks} # Only tasks currently in queue

            for task_name in task_names_in_queue:
                if task_name in self.task_registry:
                    subgraph.add_node(task_name)
                    # Add edges only if both nodes (dependency and dependent) are in the current set of tasks
                    for dep in self.task_registry[task_name].get('dependencies', []):
                        if dep in task_names_in_queue and dep in self.task_registry:
                            subgraph.add_edge(dep, task_name)
            return list(nx.topological_sort(subgraph))
        except nx.NetworkXUnfeasible:
            print("Circular dependency detected! Cannot determine a topological sort.")
            return [] # Return empty list or handle as appropriate

    def visualize_dependencies(self):
        """Generate visualization of task dependencies"""
        print("Visualization requires external libraries like matplotlib and graphviz. Not generating plot in this environment.")


class PowerOptimizer:
    """Specialized scheduler for battery-powered devices"""
    def __init__(self, hardware_profiler):
        self.hardware = hardware_profiler
        self.power_models = self._load_power_models()

    def _load_power_models(self):
        # These would be derived from empirical data or hardware specifications
        return {
            'cpu': {'active': 10.0, 'idle': 1.0}, # Watts
            'memory': {'active': 5.0, 'idle': 0.5}
        }

    def estimate_power_impact(self, task):
        """Predict power consumption for a task"""
        # Ensure 'cpu' requirement is treated as percentage for impact calculation
        cpu_req_percent = task['requirements'].get('cpu', 0)
        cpu_impact = (cpu_req_percent / 100) * self.power_models['cpu']['active']

        # Memory impact could be based on a ratio of requested memory to total memory
        total_memory_gb = self.hardware.capabilities['memory']['total'] / (1024**3) # Convert bytes to GB
        mem_req_mb = task['requirements'].get('memory', 0) # Assume MB
        mem_req_gb = mem_req_mb / 1024 # Convert MB to GB

        if total_memory_gb > 0:
            memory_impact = (mem_req_gb / total_memory_gb) * self.power_models['memory']['active']
        else:
            memory_impact = 0.0 # Avoid division by zero

        return cpu_impact + memory_impact

    def optimize_for_battery(self, tasks):
        """Reorganize tasks to minimize power impact"""
        return sorted(
            tasks,
            key=lambda x: (
                -x['priority'], # Higher priority first
                self.estimate_power_impact(x) # Then lower power impact
            )
        )

class SelfHealingSystem:
    """Automatically detects and recovers from failures"""
    def __init__(self, scheduler):
        self.scheduler = scheduler
        self.failure_patterns = []
        self.error_buffer = deque(maxlen=100)
        self._DictVectorizer = None
        self._DBSCAN = None
        try:
            from sklearn.feature_extraction import DictVectorizer
            from sklearn.cluster import DBSCAN
            self._DictVectorizer = DictVectorizer
            self._DBSCAN = DBSCAN
        except ImportError:
            print("Scikit-learn not installed. Self-healing clustering will not be available.")

    def monitor_errors(self):
        """Watch for system errors and failures (conceptual loop)"""
        while True:
            # In a real system, this would receive failure notifications from TaskExecutor
            # For this example, we'll just periodically check task history
            # and analyze new failed tasks that haven't been analyzed.
            unanalysed_failures = [
                t for t in self.scheduler.monitor.task_history
                if not t.get('success', True) and not t.get('analyzed', False)
            ]
            for task in unanalysed_failures:
                self._analyze_failure(task)
                task['analyzed'] = True # Mark as analyzed

            time.sleep(5) # Check every 5 seconds

    def _analyze_failure(self, task):
        """Determine failure pattern and suggest fixes"""
        error_signature = {
            'error_code': task.get('error_code', 'unknown'),
            'cpu_at_failure': task['metrics_at_completion'].get('cpu', 0),
            'memory_at_failure': task['metrics_at_completion'].get('memory', 0),
            'task_name': task['task']['name'] # Accessing original task name
        }
        self.error_buffer.append(error_signature)

        # Cluster similar errors
        if len(self.error_buffer) > 20 and self._DBSCAN and self._DictVectorizer:
            self._cluster_errors()

    def _cluster_errors(self):
        """Group similar errors to identify patterns"""
        vec = self._DictVectorizer(sparse=False) # sparse=False for DBSCAN
        try:
            X = vec.fit_transform(list(self.error_buffer))
        except ValueError as e:
            print(f"Error during feature transformation for clustering: {e}. Skipping clustering.")
            return

        # DBSCAN parameters might need tuning for your data
        clustering = self._DBSCAN(eps=0.5, min_samples=3).fit(X)

        for label in set(clustering.labels_):
            if label == -1: # Noise points
                continue
            cluster_errors = [e for e, l in zip(self.error_buffer, clustering.labels_)
                              if l == label]
            self._generate_solution(cluster_errors)

    def _generate_solution(self, errors_in_cluster):
        """Generate a remediation for a cluster of similar errors."""
        print(f"Detected a cluster of {len(errors_in_cluster)} similar errors. Suggesting remediation.")
        if errors_in_cluster:
            common_task_name = errors_in_cluster[0]['task_name']
            print(f"Common failed task type: {common_task_name}")
            # Example remediation: If a task consistently fails due to high CPU,
            # suggest reducing its concurrency or increasing its priority to get more resources.
            # This is where more sophisticated AI-driven remediation would go.
            print("Remediation: Consider adjusting resource limits or concurrency for this task type.")


class AITaskSchedulerComplete(AITaskScheduler):
    """Final integrated system with all advanced features"""
    def __init__(self):
        super().__init__()
        self.hardware_profiler = HardwareProfiler()
        self.context_manager = ContextManager()
        self.power_optimizer = PowerOptimizer(self.hardware_profiler)
        self.meta_learner = MetaLearner(self)
        self.self_healing = SelfHealingSystem(self)
        self.dependency_resolver = DependencyResolver()
        self.scheduling_engine = SchedulingEngine(self) # Initialize scheduling_engine here!

        # Start background services
        self._start_background_services()

    def _start_background_services(self):
        """Initialize all background optimization processes"""
        self.executor = ThreadPoolExecutor(max_workers=8)
        self.executor.submit(self.context_manager.continuous_update)
        self.executor.submit(self.meta_learner.continuous_optimization)
        self.executor.submit(self.self_healing.monitor_errors)
        self.executor.submit(self.monitor.continuous_monitoring)

    def schedule_task(self, task):
        """Enhanced scheduling with all advanced features"""
        task['created_time'] = time.time()
        self.dependency_resolver.register_task(task)

        if self.context_manager.should_defer_task(task):
            print(f"Task '{task['name']}' deferred due to context constraints.")
            self.task_queue.add_task(task)
            return {'action': 'defer', 'reason': 'context'}

        if self.context_manager.user_context['power_status'] == 'battery':
            # Re-sort the entire queue to prioritize power efficiency
            # This is a simplified approach; in a real system, this might be more nuanced.
            current_tasks_in_queue = list(self.task_queue.queue) # Get current tasks
            optimized_tasks = self.power_optimizer.optimize_for_battery(current_tasks_in_queue + [task])
            self.task_queue.queue = optimized_tasks # Replace queue with optimized order
            print(f"Power optimizer applied for task '{task['name']}'. Queue reordered.")
        else:
            self.task_queue.add_task(task) # Add normally if not on battery

        return {'action': 'added_to_queue', 'task_name': task['name']}

    def shutdown(self):
        """Gracefully shut down all services."""
        print("Initiating shutdown...")
        self.scheduling_engine.running = False # Stop the main scheduling loop
        self.monitor.stop_monitoring() # Stop continuous monitoring
        # Optionally, stop other continuous loops from meta_learner, context_manager, self_healing
        # by adding self._running flags to those classes as well.

        self.executor.shutdown(wait=True) # Wait for all submitted tasks to complete
        print("AITaskSchedulerComplete shut down.")

if __name__ == "__main__":
    print("Initializing AITaskSchedulerComplete...")
    scheduler = AITaskSchedulerComplete()

    # Example tasks
    tasks_to_add = [
        {'name': 'Data Processing', 'priority': 80, 'requirements': {'cpu': 70, 'memory': 500, 'network': 1000000}, 'estimated_duration': 5},
        {'name': 'Report Generation', 'priority': 60, 'requirements': {'cpu': 30, 'memory': 200}, 'estimated_duration': 2},
        {'name': 'Model Training', 'priority': 90, 'requirements': {'cpu': 90, 'memory': 1000, 'gpu': 1}, 'estimated_duration': 10},
        {'name': 'Cleanup Script', 'priority': 20, 'requirements': {'cpu': 10, 'memory': 50}, 'estimated_duration': 1},
        {'name': 'Network Backup', 'priority': 50, 'requirements': {'cpu': 20, 'network': 5000000}, 'dependencies': ['Data Processing'], 'estimated_duration': 7}
    ]

    for t in tasks_to_add:
        scheduler.schedule_task(t)

    # Start the scheduling engine in a separate thread
    scheduling_thread = threading.Thread(target=scheduler.scheduling_engine.run, daemon=True)
    scheduling_thread.start()

    print("Scheduler running. Press Ctrl+C to stop.")

    try:
        while True:
            time.sleep(1)
            # You can add interactive elements here, like adding new tasks
            # or querying system status.
            # print(f"Queue size: {len(scheduler.task_queue.queue)}")
            # print(f"Currently executing tasks: {list(scheduler.scheduling_engine.task_executor.current_tasks.keys())}")

    except KeyboardInterrupt:
        print("\nShutting down scheduler...")
        scheduler.shutdown()
        print("Scheduler stopped.")